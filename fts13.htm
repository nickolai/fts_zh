假设你是一具空洞的灵魂，观望着宇宙的进化。在前90亿年里，几乎什么都没有发生过。

“上帝啊，这真是<em>无聊</em>透了！”你抱怨道。

“怎么会这样呢？”于是你向同伴问道。

“任何事物都不具备深度与复杂性，因为对任何事物都没有设定<em><a href="http://lesswrong.com/lw/v9/aiming_at_the_target/">目标</a></em>。对任何事物都没有进行过<a href="http://lesswrong.com/lw/va/measuring_optimization_power/">优化</a> 。也不曾<em>规划</em>。这只不过是一堆随机产生的废物罢了。比<em>宋飞正传（美国系列喜剧）</em>还要糟糕。”

“真的？看那边，那个是什么东西呀？”

你顺着同伴的目光看过去，注意到岩态行星上，在池水里的一个小颗粒。就在你的眼前，它为自己拷贝了一个<em>复制品</em>。然后又拷贝了另一个。然后复制品又再拷贝另一个复制品。

“那是一个复制基因呢！”你惊叫起来。“几个月内它们的数量就可能会增加到<em>数百万</em>。”

“我想知道这是否会引致松鼠的变化呢?”

“什么是松鼠呀？”

于是，你的同伴又开始解释，他们在希腊厄运（Universe 217）所遇到的，松鼠的功能复杂性。

“那是<a href="http://lesswrong.com/lw/j6/why_is_the_future_so_absurd/">荒谬的</a>！按照我们当前的优化率来看，我们不会纯属偶然地看到任何<em>松鼠</em>的改变，直到很久之后宇宙热寂的出现。”

但很快地你又注意到<a href="http://lesswrong.com/lw/w0/the_first_world_takeover/">某些更为重要的东西</a>：部分的复制品是<em>次品</em>。而这些复制品正在<em>探索概念搜索空间的周边区域</em>。而部分这些区域里有更优等的复制品，而那些上好的复制品最终得到却是，比原始复制基因还更多的自体复制品，并在他们自己的社区里探索。

接下来的数十亿年，是迄今为止你所见过的、最令人兴奋的时刻。简单的复制品变成了简单的生物体，它们引领了复杂的生活，从而形成了大脑，并且进化成了<em>人类</em>行猿。

起初，<em>人类</em>看起来跟任何其他有脑的动物都非常相似。甚至与黑猩猩有着99%相同的DNA编码。如果你认为人类的大脑并不是重点，还会得到原谅——也许它也不过能使优化速度增加50%，或类似的速度。毕竟，动物的大脑已经存在了数百万年，并已逐渐进化，可在功能方面却没有任何明显的提升。

然而，<a href="http://lesswrong.com/lw/w5/cascades_cycles_insight/">一件事总会衍生出另一件事情来</a>。在你的眼前，人类开始变得聪明，他们引进了农作物，从而形成了定栖生活方式与重复性贸易，再者为了追踪债务产生了<em>文字</em>。农业形成的同时还产生了食物的盈余，从而衍生了<em>专业分工</em>，使人们<em>除了</em>寻觅食物与繁殖后代之外，还能够专攻解决问题。而专业分工则衍生出了科学技术，以及工业革命，进而步入了太空甚至发明出苹果手机。

黑猩猩与人类之间的差异，正阐明了重写机器的认知算法有多么的强大。当然，在这种情况下该算法的起源只不过是<a href="http://lesswrong.com/lw/kt/evolutions_are_stupid_but_work_anyway/">进化论、盲目与愚蠢的</a>。一个有点<em>远见</em>的<em>聪明</em>进程，可以更有效地穿越过搜索空间。一位人类计算机程序员可以在一天时间内，开拓出数十亿年的进化都不可能发现的创新技术。

但在大多数情况下，人类仍然没有弄清楚，他们<em>自身的</em>认知算法是如何工作的，或如何将其重写。而我们设计出的电脑程序却不了解<em>它们</em>自身的认知算法，或者说（<a href="http://www.amazon.com/Handbook-Metaheuristics-International-Operations-Management/dp/1441916636/">在大多数的情况下</a>）。但终有一天，<a href="http://facingthesingularity.com/2011/superstition-in-retreat/">它们能够做到</a>。

这意味着，<a href="http://lesswrong.com/lw/we/recursive_selfimprovement/">未来包含了一个过去所没有的反馈回路</a>:
<blockquote>如果你是<a href="http://lesswrong.com/lw/w6/recursion_magic/">EURISKO语言</a>，就能设法修改自己的部分启发式方法，这些启发式方法明显取得更好的成效，它们甚至还会设法对自己做进一步的修改，可到最后，整个进程却精疲力尽，步向灭亡。

开始的时候正是人类的智慧生产出这些人工产品。但其自身的优化能力却远远落后于人类——如此的乏力，在将自己向前推动一点点后，就不能再往前推进一步了。更糟糕的是，在任何既定水平中，其优化能力的最大特点是机会数量有限，意味着一旦耗尽就会消失——最后得到的是极端的收益锐减。

…当你首次制成一个人工智能机器时，它还只是一个婴儿——如果必须得改进自身，它可能会立即死亡。所以你运用自己的认知……和知识，与它共同前进——这样做并没有得到任何递推式的好处，只是用常见的人类知识习语和见解去喂养它并从见解中引发出见解。最终，这个人工智能机器变得足够成熟了，便开始进行自我改进——而且不仅是小改进，而是足以影响到其他改进的大规模改进……而你得到的却是欧文·约翰·古德（I. J. Good）口中的“<a href="http://en.wikipedia.org/wiki/Technological_singularity#Intelligence_explosion">智能爆炸</a>”…</blockquote>
…到最后，人工智能已经将我们人类的能力<a href="http://facingthesingularity.com/2011/plenty-of-room-above-us/">远远抛离其后</a>。

到了那个阶段，我们不妨效仿愚蠢的黑猩猩那样，看着那些新奇怪异的“人类”，发明火药和农业，文字、科学、枪支和飞机，紧接着接管了整个世界。正如黑猩猩一样，到那时我们将不可能与我们的上级进行谈判。我们的未来将取决于 <em>他们</em>想要的是什么。
